{
ID: 1712.08244
Title: How Well Can Generative Adversarial Networks (GAN) Learn Densities: A Nonparametric View
Authors: Tengyuan Liang
Date: 2017/12/21
Abstract: We study in this paper the rate of convergence for learning densities under the Generative Adversarial Networks (GANs) framework, borrowing insights from nonparametric statistics. We introduce an improved GAN estimator that achieves a faster rate, through leveraging the level of smoothness in the target density and the evaluation metric, which in theory remedies the mode collapse problem reported in the literature. A minimax lower bound is constructed to show that when the dimension is large, the exponent in the rate for the new GAN estimator is near optimal. One can view our results as answering in a quantitative way how well GAN learns a wide range of densities with different smoothness properties, under a hierarchy of evaluation metrics. As a byproduct, we also obtain improved bounds for GAN with deeper ReLU discriminator network.
Subjects: stat.ML, cs.LG, math.ST
Tags: 
}{
ID: 1712.08124
Title: Phonon transport unveils the prevalent point defects in GaN
Authors: Ankita Katre, Jes?s Carrete, Tao Wang, Georg K. H. Madsen, Natalio Mingo
Date: 2017/12/21
Abstract: Determining the types and concentrations of vacancies present in intentionally doped GaN is a notoriously difficult and long-debated problem. Here we use an unconventional approach, based on thermal transport modeling, to determine the prevalence of vacancies in previous measurements. This allows us to provide conclusive evidence of the recent hypothesis that gallium vacancies in ammonothermally grown samples can be complexed with hydrogen. Our calculations for O-doped and Mg-O co-doped samples yield a consistent picture interlinking dopant and vacancy concentration, carrier density, and thermal conductivity, in excellent agreement with experimental measurements. These results also highlight the predictive power of ab initio phonon transport modeling, and its value for understanding and quantifying defects in semiconductors.
Subjects: cond-mat.mtrl-sci
Tags: 
}{
ID: 1712.09553
Title: DeepIEP: a Peptide Sequence Model of Isoelectric Point (IEP/pI) using Recurrent Neural Networks (RNNs)
Authors: Esben Jannik Bjerrum
Date: 2017/12/27
Abstract: The isoelectric point (IEP or pI) is the pH where the net charge on the molecular ensemble of peptides and proteins is zero. This physical-chemical property is dependent on protonable/deprotonable sidechains and their pKa values. Here an pI prediction model is trained from a database of peptide sequences and pIs using a recurrent neural network (RNN) with long short-term memory (LSTM) cells. The trained model obtains an RMSE and R$^2$ of 0.28 and 0.95 for the external test set. The model is not based on pKa values, but prediction of constructed test sequences show similar rankings as already known pKa values. The prediction depends mostly on the existence of known acidic and basic amino acids with fine-adjusted based on the neighboring sequence and position of the charged amino acids in the peptide chain.
Subjects: q-bio.BM, cs.LG, q-bio.QM
Tags: 
}{
ID: 1712.09185
Title: Actionable Email Intent Modeling with Reparametrized RNNs
Authors: Chu-Cheng Lin, Dongyeop Kang, Michael Gamon, Madian Khabsa, Ahmed Hassan Awadallah, Patrick Pantel
Date: 2017/12/26
Abstract: Emails in the workplace are often intentional calls to action for its recipients. We propose to annotate these emails for what action its recipient will take. We argue that our approach of action-based annotation is more scalable and theory-agnostic than traditional speech-act-based email intent annotation, while still carrying important semantic and pragmatic information. We show that our action-based annotation scheme achieves good inter-annotator agreement. We also show that we can leverage threaded messages from other domains, which exhibit comparable intents in their conversation, with domain adaptive RAINBOW (Recurrently AttentIve Neural Bag-Of-Words). On a collection of datasets consisting of IRC, Reddit, and email, our reparametrized RNNs outperform common multitask/multidomain approaches on several speech act related tasks. We also experiment with a minimally supervised scenario of email recipient action classification, and find the reparametrized RNNs learn a useful representation.
Subjects: cs.CL
Tags: 
}{
ID: 1712.07316
Title: A Flexible Approach to Automated RNN Architecture Generation
Authors: Martin Schrimpf, Stephen Merity, James Bradbury, Richard Socher
Date: 2017/12/20
Abstract: The process of designing neural architectures requires expert knowledge and extensive trial and error. While automated architecture search may simplify these requirements, the recurrent neural network (RNN) architectures generated by existing methods are limited in both flexibility and components. We propose a domain-specific language (DSL) for use in automated architecture search which can produce novel RNNs of arbitrary depth and width. The DSL is flexible enough to define standard architectures such as the Gated Recurrent Unit and Long Short Term Memory and allows the introduction of non-standard RNN components such as trigonometric curves and layer normalization. Using two different candidate generation techniques, random search with a ranking function and reinforcement learning, we explore the novel architectures produced by the RNN DSL for language modeling and machine translation domains. The resulting architectures do not follow human intuition yet perform well on their targeted tasks, suggesting the space of usable RNN architectures is far larger than previously assumed.
Subjects: cs.CL, cs.LG, stat.ML
Tags: 
}{
ID: 1712.05109
Title: Online Motion Generation with Sensory Information and Instructions by Hierarchical RNN
Authors: Kanata Suzuki, Hiroki Mori, Tetsuya Ogata
Date: 2017/12/14
Abstract: This paper proposes an approach for robots to perform co-working task alongside humans by using neuro-dynamical models. The proposed model comprised two models: an Autoencoder and a hierarchical recurrent neural network (RNN). We trained hierarchical RNN with various sensory-motor sequences and instructions. To acquire the interactive ability to switch and combine appropriate motions according to visual information and instructions from outside, we embedded the cyclic neuronal dynamics in a network. To evaluate our model, we designed a cloth-folding task that consists of four short folding motions and three patterns of instruction that indicate the direction of each short motion. The results showed that the robot can perform the task by switching or combining short motions with instructions and visual information. We also showed that the proposed model acquired relationships between the instructions and sensory-motor information in its internal neuronal dynamics. Supplementary video: this https URL
Subjects: cs.RO
Tags: 
}{
ID: 1712.03941
Title: Fast Nearest-Neighbor Classification using RNN in Domains with Large Number of Classes
Authors: Gautam Singh, Gargi Dasgupta, Yu Deng
Date: 2017/12/11
Abstract: In scenarios involving text classification where the number of classes is large (in multiples of 10000s) and training samples for each class are few and often verbose, nearest neighbor methods are effective but very slow in computing a similarity score with training samples of every class. On the other hand, machine learning models are fast at runtime but training them adequately is not feasible using few available training samples per class. In this paper, we propose a hybrid approach that cascades 1) a fast but less-accurate recurrent neural network (RNN) model and 2) a slow but more-accurate nearest-neighbor model using bag of syntactic features. Using the cascaded approach, our experiments, performed on data set from IT support services where customer complaint text needs to be classified to return top-$N$ possible error codes, show that the query-time of the slow system is reduced to $1/6^{th}$ while its accuracy is being improved. Our approach outperforms an LSH-based baseline for query-time reduction. We also derive a lower bound on the accuracy of the cascaded model in terms of the accuracies of the individual models. In any two-stage approach, choosing the right number of candidates to pass on to the second stage is crucial. We prove a result that aids in choosing this cutoff number for the cascaded system.
Subjects: cs.IR
Tags: 
}{
ID: 1711.04569
Title: Multilingual Adaptation of RNN Based ASR Systems
Authors: Markus M?ller, Sebastian St?ker, Alex Waibel
Date: 2017/11/13
Abstract: A large amount of data is required for automatic speech recognition (ASR) systems achieving good performance. While such data is readily available for languages like English, there exists a long tail of languages with only limited language resources. By using data from additional source languages, this problem can be mitigated. In this work, we focus on multilingual systems based on recurrent neural networks (RNNs), trained using the Connectionist Temporal Classification (CTC) loss function. Using a multilingual set of acoustic units to train systems jointly on multiple languages poses difficulties: While the same phones share the same symbols across languages, they are pronounced slightly different because of, e.g., small shifts in tongue positions. To address this issue, we proposed Language Feature Vectors (LFVs) to train language adaptive multilingual systems. In this work, we extended this approach by introducing a novel technique which we call "modulation" to add LFVs . We evaluated our approach in multiple conditions, showing improvements in both full and low resource conditions as well as for grapheme and phone based systems.
Subjects: eess.AS, cs.AI, cs.CL
Tags: 
}{
ID: 1711.04480
Title: Audio-to-score alignment of piano music using RNN-based automatic music transcription
Authors: Taegyun Kwon, Dasaem Jeong, Juhan Nam
Date: 2017/11/13
Abstract: We propose a framework for audio-to-score alignment on piano performance that employs automatic music transcription (AMT) using neural networks. Even though the AMT result may contain some errors, the note prediction output can be regarded as a learned feature representation that is directly comparable to MIDI note or chroma representation. To this end, we employ two recurrent neural networks that work as the AMT-based feature extractors to the alignment algorithm. One predicts the presence of 88 notes or 12 chroma in frame-level and the other detects note onsets in 12 chroma. We combine the two types of learned features for the audio-to-score alignment. For comparability, we apply dynamic time warping as an alignment algorithm without any additional post-processing. We evaluate the proposed framework on the MAPS dataset and compare it to previous work. The result shows that the alignment framework with the learned features significantly improves the accuracy, achieving less than 10 ms in mean onset error.
Subjects: cs.SD, eess.AS
Tags: 
}{
ID: 1711.06778
Title: Excitation Backprop for RNNs
Authors: Sarah Adel Bargal, Andrea Zunino, Donghyun Kim, Jianming Zhang, Vittorio Murino, Stan Sclaroff
Date: 2017/11/18
Abstract: Deep models are state-of-the-art for many vision tasks including video action recognition and video captioning. Models are trained to caption or classify activity in videos, but little is known about the evidence used to make such decisions. Grounding decisions made by deep networks has been studied in spatial visual content, giving more insight into model predictions for images. However, such studies are relatively lacking for models of spatiotemporal visual content - videos. In this work, we devise a formulation that simultaneously grounds evidence in space and time, in a single pass, using top-down saliency. We visualize the spatiotemporal cues that contribute to a deep model's classification/captioning output using the model's internal representation. Based on these spatiotemporal cues, we are able to localize segments within a video that correspond with a specific action, or phrase from a caption, without explicitly optimizing/training for these tasks.
Subjects: cs.CV
Tags: 
}{
ID: 1712.09662
Title: CNN Is All You Need
Authors: Qiming Chen, Ren Wu
Date: 2017/12/27
Abstract: The Convolution Neural Network (CNN) has demonstrated the unique advantage in audio, image and text learning; recently it has also challenged Recurrent Neural Networks (RNNs) with long short-term memory cells (LSTM) in sequence-to-sequence learning, since the computations involved in CNN are easily parallelizable whereas those involved in RNN are mostly sequential, leading to a performance bottleneck. However, unlike RNN, the native CNN lacks the history sensitivity required for sequence transformation; therefore enhancing the sequential order awareness, or position-sensitivity, becomes the key to make CNN the general deep learning model. In this work we introduce an extended CNN model with strengthen position-sensitivity, called PoseNet. A notable feature of PoseNet is the asymmetric treatment of position information in the encoder and the decoder. Experiments shows that PoseNet allows us to improve the accuracy of CNN based sequence-to-sequence learning significantly, achieving around 33-36 BLEU scores on the WMT 2014 English-to-German translation task, and around 44-46 BLEU scores on the English-to-French translation task.
Subjects: cs.CL, cs.LG, cs.NE
Tags: 
}{
ID: 1412.7927
Title: Polyphonic Music Generation by Modeling Temporal Dependencies Using a RNN-DBN
Authors: Kratarth Goel, Raunaq Vohra, J.K. Sahoo
Date: 2014/12/26
Abstract: In this paper, we propose a generic technique to model temporal dependencies and sequences using a combination of a recurrent neural network and a Deep Belief Network. Our technique, RNN-DBN, is an amalgamation of the memory state of the RNN that allows it to provide temporal information and a multi-layer DBN that helps in high level representation of the data. This makes RNN-DBNs ideal for sequence generation. Further, the use of a DBN in conjunction with the RNN makes this model capable of significantly more complex data representation than an RBM. We apply this technique to the task of polyphonic music generation.
Subjects: cs.LG, cs.AI, cs.NE
Tags: 
}